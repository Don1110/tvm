{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec96063a",
   "metadata": {},
   "source": [
    "# 加法示例 - CUDA\n",
    "参考：\n",
    "- https://tvm.apache.org/docs/dev/tutorial/codebase_walkthrough.html\n",
    "- gallery/tutorial/tensor_expr_get_started.py\n",
    "- coureDLC,7\n",
    "- tvm\\tests\\python\\unittest\\test_lower_build.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb65e9",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "```\n",
    "os.environ['PYTHONPATH']='D:\\\\Dev\\\\tvm\\\\python'\n",
    "print(os.environ.get('PYTHONPATH'))\n",
    "\n",
    "print(os.environ.get('PATH'))\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "print(os.environ.get('PYTHONPATH'))\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "\n",
    "\n",
    "sys.path.pop()\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "os.environ['PATH'] += ';D:\\\\Dev\\\\tvm\\\\build\\\\Release'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9a343fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "from tvm.ir.module import IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d01efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a26eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1024\n",
    "\n",
    "target = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebb17829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import tir as T\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer[1024, \"float32\"], B: T.Buffer[1024, \"float32\"], C: T.Buffer[1024, \"float32\"]):\n",
      "        # function attr dict\n",
      "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with T.block(\"root\")\n",
      "        for i in T.serial(1024):\n",
      "            with T.block(\"C\"):\n",
      "                v_i = T.axis.spatial(1024, i)\n",
      "                T.reads(A[v_i], B[v_i])\n",
      "                T.writes(C[v_i])\n",
      "                C[v_i] = A[v_i] + B[v_i]\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev = tvm.device(target, 0)\n",
    "\n",
    "# declare the computation using the expression API\n",
    "A = te.placeholder((n, ), name=\"A\")\n",
    "B = te.placeholder((n, ), name=\"B\")\n",
    "C = te.compute((n,), lambda i: A[i] + B[i], name=\"C\")\n",
    "\n",
    "# Default schedule\n",
    "func = te.create_prim_func([A, B, C])\n",
    "func = func.with_attr(\"global_symbol\", \"main\")\n",
    "ir_module = IRModule({\"main\": func})\n",
    "print(ir_module.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbdd8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvm.tir.Schedule??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29fda76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a TensorIR schedule class from an IRModule\n",
    "sch = tvm.tir.Schedule(ir_module) \n",
    "# Get block by its name\n",
    "block_c = sch.get_block(\"C\")\n",
    "# Get loops surronding the block\n",
    "(i,) = sch.get_loops(block_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4d01618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import tir as T\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer[1024, \"float32\"], B: T.Buffer[1024, \"float32\"], C: T.Buffer[1024, \"float32\"]):\n",
      "        # function attr dict\n",
      "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with T.block(\"root\")\n",
      "        for i in T.thread_binding(1024, thread=\"threadIdx.x\"):\n",
      "            with T.block(\"C\"):\n",
      "                v_i = T.axis.spatial(1024, i)\n",
      "                T.reads(A[v_i], B[v_i])\n",
      "                T.writes(C[v_i])\n",
      "                C[v_i] = A[v_i] + B[v_i]\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sch.bind(i, \"threadIdx.x\")\n",
    "print(sch.mod.script())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad376c",
   "metadata": {},
   "source": [
    "这里的线程绑定操作，最终到cuda代码的映射操作是在代码生成阶段完成。\n",
    "```c++\n",
    "// src/target/source/codegen_cuda.cc\n",
    "\n",
    "class ThreadIdxExtractor : public tir::StmtVisitor {\n",
    " private:\n",
    "  void VisitStmt_(const AttrStmtNode* op) final {\n",
    "    if (op->attr_key == tir::attr::thread_extent) {\n",
    "      IterVar iv = Downcast<IterVar>(op->node);\n",
    "      if (iv->var->name_hint == \"threadIdx.x\" || iv->thread_tag == \"threadIdx.x\") {\n",
    "        threadIdx_x_ext = op->value;\n",
    "      }\n",
    "      if (iv->var->name_hint == \"threadIdx.y\" || iv->thread_tag == \"threadIdx.y\") {\n",
    "        threadIdx_y_ext = op->value;\n",
    "      }\n",
    "      if (iv->var->name_hint == \"threadIdx.z\" || iv->thread_tag == \"threadIdx.z\") {\n",
    "        threadIdx_z_ext = op->value;\n",
    "      }\n",
    "    }\n",
    "    StmtVisitor::VisitStmt_(op);\n",
    "  }\n",
    "\n",
    " public:\n",
    "  PrimExpr threadIdx_x_ext = Integer(1);\n",
    "  PrimExpr threadIdx_y_ext = Integer(1);\n",
    "  PrimExpr threadIdx_z_ext = Integer(1);\n",
    "};\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5138d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fadd = tvm.build(sch.mod, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e3883c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module(cuda, 18370048f78)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fadd.imported_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eda3cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#ifdef _WIN32\n",
      "  using uint = unsigned int;\n",
      "  using uchar = unsigned char;\n",
      "  using ushort = unsigned short;\n",
      "  using int64_t = long long;\n",
      "  using uint64_t = unsigned long long;\n",
      "#else\n",
      "  #define uint unsigned int\n",
      "  #define uchar unsigned char\n",
      "  #define ushort unsigned short\n",
      "  #define int64_t long long\n",
      "  #define uint64_t unsigned long long\n",
      "#endif\n",
      "extern \"C\" __global__ void __launch_bounds__(1024) main_kernel0(float* __restrict__ C, float* __restrict__ A, float* __restrict__ B) {\n",
      "  C[((int)threadIdx.x)] = (A[((int)threadIdx.x)] + B[((int)threadIdx.x)]);\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fadd.imported_modules[0].get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be4a3b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.driver.build_module.OperatorModule"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d31eccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev) #在目标设备分配相应空间，并将数据填入。\n",
    "b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
    "c = tvm.nd.array(np.zeros(n, dtype=C.dtype), dev)\n",
    "fadd(a, b, c)\n",
    "output = c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7cf5a2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.000034\n"
     ]
    }
   ],
   "source": [
    "evaluator = fadd.time_evaluator(fadd.entry_name, dev, number=1)\n",
    "print(\"Baseline: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc101015",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_nvptx = tvm.target.Target(\"nvptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cdae570",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdd_nvptx = tvm.build(sch.mod, target=tgt_nvptx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e03b231b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'; ModuleID = \\'TVMPTXModule\\'\\nsource_filename = \"TVMPTXModule\"\\ntarget datalayout = \"e-i64:64-i128:128-v16:16-v32:32-n16:32:64\"\\ntarget triple = \"nvptx64-nvidia-cuda\"\\n\\n; Function Attrs: mustprogress nofree nosync nounwind willreturn\\ndefine dllexport void @main_kernel0(float* noalias nocapture writeonly %C, float* noalias nocapture readonly %A, float* noalias nocapture readonly %B) local_unnamed_addr #0 {\\nentry:\\n  %0 = tail call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !2\\n  %1 = zext i32 %0 to i64\\n  %2 = getelementptr inbounds float, float* %B, i64 %1\\n  %3 = load float, float* %2, align 4, !tbaa !3\\n  %4 = getelementptr inbounds float, float* %A, i64 %1\\n  %5 = load float, float* %4, align 4, !tbaa !6\\n  %6 = fadd float %3, %5\\n  %7 = getelementptr inbounds float, float* %C, i64 %1\\n  store float %6, float* %7, align 4, !tbaa !8\\n  ret void\\n}\\n\\n; Function Attrs: nofree nosync nounwind readnone speculatable\\ndeclare i32 @llvm.nvvm.read.ptx.sreg.tid.x() #1\\n\\n; Function Attrs: nofree nosync nounwind readnone\\ndefine weak dso_local i16 @__truncsfhf2(float %a0) local_unnamed_addr #2 section \".text.tvm.fp16.conv\" {\\nb0:\\n  %v0 = bitcast float %a0 to i32\\n  %v1 = and i32 %v0, 2147483647\\n  %v2 = add nsw i32 %v1, -947912704\\n  %v3 = add nsw i32 %v1, -1199570944\\n  %v4 = icmp ult i32 %v2, %v3\\n  br i1 %v4, label %b1, label %b5\\n\\nb1:                                               ; preds = %b0\\n  %v5 = lshr i32 %v0, 13\\n  %v6 = and i32 %v5, 65535\\n  %v7 = add nuw nsw i32 %v6, -114688\\n  %v8 = and i32 %v0, 8191\\n  %v9 = icmp ugt i32 %v8, 4096\\n  br i1 %v9, label %b2, label %b3\\n\\nb2:                                               ; preds = %b1\\n  %v10 = add nuw nsw i32 %v6, -114687\\n  br label %b13\\n\\nb3:                                               ; preds = %b1\\n  %v11 = icmp eq i32 %v8, 4096\\n  %v12 = and i32 %v7, 65535\\n  %v13 = and i32 %v5, 1\\n  %v14 = add nuw nsw i32 %v12, %v13\\n  %spec.select = select i1 %v11, i32 %v14, i32 %v7\\n  br label %b13\\n\\nb5:                                               ; preds = %b0\\n  %v15 = icmp ugt i32 %v1, 2139095040\\n  br i1 %v15, label %b6, label %b7\\n\\nb6:                                               ; preds = %b5\\n  %v16 = lshr i32 %v0, 13\\n  %v17 = and i32 %v16, 511\\n  %v18 = or i32 %v17, 32256\\n  br label %b13\\n\\nb7:                                               ; preds = %b5\\n  %v19 = icmp ugt i32 %v1, 1199570943\\n  br i1 %v19, label %b13, label %b8\\n\\nb8:                                               ; preds = %b7\\n  %v20 = icmp ult i32 %v1, 754974720\\n  br i1 %v20, label %b13, label %b9\\n\\nb9:                                               ; preds = %b8\\n  %v21 = lshr i32 %v1, 23\\n  %v22 = sub nsw i32 113, %v21\\n  %v23 = and i32 %v0, 8388607\\n  %v24 = or i32 %v23, 8388608\\n  %v25 = add nsw i32 %v21, -81\\n  %v26 = shl i32 %v24, %v25\\n  %v27 = icmp ne i32 %v26, 0\\n  %v28 = lshr i32 %v24, %v22\\n  %v29 = zext i1 %v27 to i32\\n  %v30 = lshr i32 %v28, 13\\n  %v31 = and i32 %v28, 8191\\n  %v32 = or i32 %v31, %v29\\n  %v33 = icmp ugt i32 %v32, 4096\\n  br i1 %v33, label %b10, label %b11\\n\\nb10:                                              ; preds = %b9\\n  %v34 = add nuw nsw i32 %v30, 1\\n  br label %b13\\n\\nb11:                                              ; preds = %b9\\n  %v35 = icmp eq i32 %v32, 4096\\n  %v36 = and i32 %v30, 1\\n  %v37 = select i1 %v35, i32 %v36, i32 0\\n  %spec.select1 = add nuw nsw i32 %v37, %v30\\n  br label %b13\\n\\nb13:                                              ; preds = %b11, %b3, %b10, %b8, %b7, %b6, %b2\\n  %v38 = phi i32 [ %v18, %b6 ], [ %v10, %b2 ], [ 31744, %b7 ], [ 0, %b8 ], [ %v34, %b10 ], [ %spec.select, %b3 ], [ %spec.select1, %b11 ]\\n  %v39 = lshr i32 %v0, 16\\n  %v40 = and i32 %v39, 32768\\n  %v41 = or i32 %v38, %v40\\n  %vlast = trunc i32 %v41 to i16\\n  ret i16 %vlast\\n}\\n\\n; Function Attrs: nofree nosync nounwind readnone\\ndefine weak dso_local float @__extendhfsf2(i16 %a0) local_unnamed_addr #2 section \".text.tvm.fp16.conv\" {\\nb0:\\n  %v1 = and i16 %a0, 32767\\n  %v2 = zext i16 %v1 to i32\\n  %v3 = add nsw i16 %v1, -1024\\n  %v4 = icmp ult i16 %v3, 30720\\n  br i1 %v4, label %b1, label %b2\\n\\nb1:                                               ; preds = %b0\\n  %v5 = shl nuw nsw i32 %v2, 13\\n  %v6 = add nuw nsw i32 %v5, 939524096\\n  br label %b6\\n\\nb2:                                               ; preds = %b0\\n  %v7 = icmp ugt i16 %v1, 31743\\n  br i1 %v7, label %b3, label %b4\\n\\nb3:                                               ; preds = %b2\\n  %v8 = shl nuw nsw i32 %v2, 13\\n  %v9 = or i32 %v8, 2139095040\\n  br label %b6\\n\\nb4:                                               ; preds = %b2\\n  %v10 = icmp eq i16 %v1, 0\\n  br i1 %v10, label %b6, label %b5\\n\\nb5:                                               ; preds = %b4\\n  %v11 = icmp ult i16 %v1, 256\\n  %v12 = lshr i32 %v2, 8\\n  %v13 = select i1 %v11, i32 %v2, i32 %v12\\n  %v14 = select i1 %v11, i32 32, i32 24\\n  %v15 = icmp ult i32 %v13, 16\\n  %v16 = lshr i32 %v13, 4\\n  %v17 = add nsw i32 %v14, -4\\n  %v18 = select i1 %v15, i32 %v13, i32 %v16\\n  %v19 = select i1 %v15, i32 %v14, i32 %v17\\n  %v20 = icmp ult i32 %v18, 4\\n  %v21 = lshr i32 %v18, 2\\n  %v22 = add nsw i32 %v19, -2\\n  %v23 = select i1 %v20, i32 %v18, i32 %v21\\n  %v24 = select i1 %v20, i32 %v19, i32 %v22\\n  %v25 = icmp ult i32 %v23, 2\\n  %v26 = sub nsw i32 0, %v23\\n  %v27 = select i1 %v25, i32 %v26, i32 -2\\n  %v28 = add nsw i32 %v27, %v24\\n  %v29 = add nsw i32 %v28, -8\\n  %v30 = shl i32 %v2, %v29\\n  %v31 = xor i32 %v30, 8388608\\n  %v32.neg = mul i32 %v28, -8388608\\n  %v33 = add i32 %v32.neg, 1124073472\\n  %v34 = or i32 %v31, %v33\\n  br label %b6\\n\\nb6:                                               ; preds = %b5, %b4, %b3, %b1\\n  %v35 = phi i32 [ %v6, %b1 ], [ %v9, %b3 ], [ %v34, %b5 ], [ 0, %b4 ]\\n  %v36 = and i16 %a0, -32768\\n  %v37 = zext i16 %v36 to i32\\n  %v38 = shl nuw i32 %v37, 16\\n  %v39 = or i32 %v35, %v38\\n  %v40 = bitcast i32 %v39 to float\\n  ret float %v40\\n}\\n\\nattributes #0 = { mustprogress nofree nosync nounwind willreturn \"target-cpu\"=\"sm_75\" }\\nattributes #1 = { nofree nosync nounwind readnone speculatable }\\nattributes #2 = { nofree nosync nounwind readnone \"target-cpu\"=\"sm_75\" \"target-features\" }\\n\\n!nvvm.annotations = !{!0}\\n!llvm.ident = !{!1}\\n\\n!0 = !{void (float*, float*, float*)* @main_kernel0, !\"kernel\", i32 1}\\n!1 = !{!\"clang version 3.8.0 \"}\\n!2 = !{i32 0, i32 1024}\\n!3 = !{!4, !4, i64 0}\\n!4 = !{!\"0000018370632850\", !5, i64 0}\\n!5 = !{!\"tvm-tbaa\"}\\n!6 = !{!7, !7, i64 0}\\n!7 = !{!\"0000018370631D50\", !5, i64 0}\\n!8 = !{!9, !9, i64 0}\\n!9 = !{!\"00000183706320D0\", !5, i64 0}\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdd_nvptx.imported_modules[0].get_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "070e3e39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.000035\n"
     ]
    }
   ],
   "source": [
    "evaluator = fadd.time_evaluator(fdd_nvptx.entry_name, dev, number=1)\n",
    "print(\"Baseline: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51947e0a",
   "metadata": {},
   "source": [
    "# 矩阵乘法 - CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd7076",
   "metadata": {},
   "source": [
    "# 加法示例- SDAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b51f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cuda = tvm.target.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d96233e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuda -keys=cuda,gpu -arch=sm_75 -max_num_threads=1024 -model=unknown -thread_warp_size=32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e4b1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt, t_host = target_cuda.canon_target_and_host(target_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f928527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda -keys=cuda,gpu -arch=sm_75 -max_num_threads=1024 -model=unknown -thread_warp_size=32\n"
     ]
    }
   ],
   "source": [
    "print(tgt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
